---
title: SongScore 알고리즘
published: 2024-12-30
description: "유튜브 음악과 부른 노래 음성의 유사도를 추출하는 알고리즘 소개"
tags: ["SongScore"]
category: Project
draft: false
---

## SongScore의 대략적인 알고리즘 흐름
1. 유튜브 음악을 가져옵니다.
2. 유튜브 음악에서 보컬을 추출합니다.
3. 보컬 음성 2개를 멜스펙트로그램으로 바꿉니다.
4. 두 멜스펙트로그램을 비교합니다.

SongScore는 이러한 흐름으로 구현되어있습니다.

### 보컬 추출 알고리즘

보컬 추출 알고리즘은 TFC_TDF_UNET V3라는 Convoution Layer 기반 아키텍처 모델을 사용하였습니다.

모델은 이하 레포지토리의 미리 학습된 모델을 사용하였습니다.

::github{repo="kuielab/sdx23"}

*변경 가능성 있음*

### 멜스펙트로그램 변경 알고리즘

멜스펙트로그램 변경 알고리즘은 기본적으로 푸리에 변환을 기반으로 작동합니다.  

푸리에변환은 간단히 말하자면 시간에 관한 함수(정의역이 시간)을 주파수에 관한 함수(정의역이 주파수)에 관한 함수로 바꾸는 변환입니다. 

푸리에 변환에 관한 자세한 사항은 아래 영상에 나와있습니다.

<iframe width="100%" height="468" src="https://youtu.be/Mc9PHZ3H36M" title="YouTube video player" frameborder="0" allowfullscreen></iframe>

이 것이 가능한 이유는 모든 신호는 원본에 더해지는 사인파 및 코사인파로 분해될 수 있기 때문입니다.  
여기서 신호를 푸리에 변환한 것을 스펙트럼이라 합니다.  
하지만 음악이나 발화와 같은 일상의 음성 데이터는 주파수가 시간에 따라 계속 변화합니다.  
즉 이것을 해결하기 위하여 시간에 따라 달라지는 신호의 스펙트럼을 나타내는 방법이 필요하게 됩니다.
이 문제를 해결할려고 생각을 한 결과 신호의 여러 시점에서 FFT(Fast Fourier Transform; 고속 푸리에 변환)을 하는 방법을 생각하였습니다.  
신호의 여러 시점에서 변환한걸 묶은 것이 스펙트로그램입니다.
이 스펙트로그램은 선형적으로 주파수의 간격이 띄워져 있지만 사람의 귀가 듣는 주파수는 선형적이지 않기에 사람의 귀에 맞는 스케일로 바꾼게 멜스펙트로그램입니다.

### 멜스펙트로그램 비교 알고리즘

멜스펙트로그램은 축으로 따지면 시간, 주파수, 소리크기라는 축으로 되어있습니다.  
다른 말로 하자면 x축이 주파수, y축이 소리크기, z축이 시간으로 되어있는 그래프의 찍힌 점들의 모임이라고도 이야기 가능합니다.  
여기서 같은 시간일때 비슷한 크기의 소리로 비슷한 주파수를 낸다면 그것이 원본 노래와 유사할 수 있다는 아이디어로 알고리즘을 떠올렸습니다.  
이 일을 해내기 위하여 저희는 코사인 유사도(Cosine Similiarity)를 사용했습니다.  
코사인 유사도는 두 벡터 사이의 각도를 구하는 방법으로 두 벡터를 a, b, 사잇각을 $$\alpha$$라 할때 식은 다음과 같습니다.  
$$Cosine \space Similarity = \frac{a \cdot b}{\lVert a \rVert \lVert b \rVert}$$
여기서 $$a \cdot b$$는 두 벡터의 내적이고 $$\lVert a \rVert$$는 벡터의 노름, 길이입니다.
이 방식으로 두 벡터 사이의 각을 구해 유사도를 구하고 점수를 구할 수 있습니다.
